{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import cv2\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from tools_copy.settings import *\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tools_copy.train_val_test_spliter import split\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the ginen dataset into Train Test=0.2 Validation=0.2\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd. read_csv(os.path.join(dataset_path, \"train.csv\"))\n",
    "test = pd. read_csv(os.path.join(dataset_path, \"test.csv\"))\n",
    "val = pd. read_csv(os.path.join(dataset_path, \"val.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_url</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\kill/Kill_13.mp4</td>\n",
       "      <td>kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\smoke/smoke_25 .mp4</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\kill/Kill_34.mp4</td>\n",
       "      <td>kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\smoke/smoke_33 .mp4</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\smoke/smoke_106 .mp4</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Video_url action\n",
       "0      E:\\Project 103\\Trimmed Data\\kill/Kill_13.mp4   kill\n",
       "1   E:\\Project 103\\Trimmed Data\\smoke/smoke_25 .mp4  smoke\n",
       "2      E:\\Project 103\\Trimmed Data\\kill/Kill_34.mp4   kill\n",
       "3   E:\\Project 103\\Trimmed Data\\smoke/smoke_33 .mp4  smoke\n",
       "4  E:\\Project 103\\Trimmed Data\\smoke/smoke_106 .mp4  smoke"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_url</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\smoke/smoke_57 .mp4</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\death/death_63.mp4</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\kill/Kill_2.mp4</td>\n",
       "      <td>kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\kill/Kill_65.mp4</td>\n",
       "      <td>kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\smoke/smoke_19 .mp4</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Video_url action\n",
       "0  E:\\Project 103\\Trimmed Data\\smoke/smoke_57 .mp4  smoke\n",
       "1   E:\\Project 103\\Trimmed Data\\death/death_63.mp4  death\n",
       "2      E:\\Project 103\\Trimmed Data\\kill/Kill_2.mp4   kill\n",
       "3     E:\\Project 103\\Trimmed Data\\kill/Kill_65.mp4   kill\n",
       "4  E:\\Project 103\\Trimmed Data\\smoke/smoke_19 .mp4  smoke"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_url</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\smoke/smoke_90 .mp4</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\kill/Kill_57.mp4</td>\n",
       "      <td>kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\smoke/smoke_93 .mp4</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\smoke/smoke_65 .mp4</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\kill/Kill_64.mp4</td>\n",
       "      <td>kill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Video_url action\n",
       "0  E:\\Project 103\\Trimmed Data\\smoke/smoke_90 .mp4  smoke\n",
       "1     E:\\Project 103\\Trimmed Data\\kill/Kill_57.mp4   kill\n",
       "2  E:\\Project 103\\Trimmed Data\\smoke/smoke_93 .mp4  smoke\n",
       "3  E:\\Project 103\\Trimmed Data\\smoke/smoke_65 .mp4  smoke\n",
       "4     E:\\Project 103\\Trimmed Data\\kill/Kill_64.mp4   kill"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 2)\n",
      "(61, 2)\n",
      "(61, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_frame(data, folder_name):\n",
    "    '''\n",
    "    Generated filenames format dataset_path/folder_name/video_name_frame{number}_action.jpg\n",
    "    '''\n",
    "    directory = os.path.join(dataset_path, folder_name)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    for i in tqdm(range(data.shape[0])):\n",
    "        video_file = data['Video_url'][i]\n",
    "        action = data['action'][i]\n",
    "        video_name_list = video_file.split('/')[-1].split('.')\n",
    "        video_name_list = video_name_list[:-1]\n",
    "        video_name = \"\"\n",
    "        for n in video_name_list:\n",
    "            video_name += n\n",
    "        # capturing the video from the given path\n",
    "        capture = cv2.VideoCapture(video_file) \n",
    "        #frame rate\n",
    "        frame_rate = capture.get(5)\n",
    "        count = 0\n",
    "        while(capture.isOpened()):\n",
    "            #current frame number\n",
    "            frame_id = capture.get(1) \n",
    "            read_correctly, frame = capture.read()\n",
    "            if not read_correctly:\n",
    "                break\n",
    "            if (frame_id % math.floor(frame_rate) == 0):\n",
    "                # storing the frames in a new folder named train_1\n",
    "                filename = directory + \"/\" + video_name + \"_frame{}_\".format(count) + action +\".jpg\"\n",
    "                count += 1\n",
    "                cv2.imwrite(filename, frame)\n",
    "        capture.release()\n",
    "    print(\"Successfully Converted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [02:32<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Converted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_to_frame(train, train_frames_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:43<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Converted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_to_frame(val, val_frames_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paths_csv(directory, file_name):\n",
    "    images = os.listdir(directory)\n",
    "    images_path_list = []\n",
    "    images_action_list = [] \n",
    "    for image in images:\n",
    "        images_path_list.append(directory + image)\n",
    "        images_action_list.append(image.split('.')[0].split('_')[-1])\n",
    "    df = pd.DataFrame()\n",
    "    df['image'] = images_path_list\n",
    "    df['action'] = images_action_list\n",
    "    print(os.path.join(dataset_path, file_name+'.csv'))\n",
    "    df.to_csv(os.path.join(dataset_path, file_name+'.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Project 103\\Trimmed Data\\train_frames.csv\n"
     ]
    }
   ],
   "source": [
    "create_paths_csv(train_frames_path, train_frames_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Project 103\\Trimmed Data\\val_frames.csv\n"
     ]
    }
   ],
   "source": [
    "create_paths_csv(val_frames_path, val_frames_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\death...</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\death...</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\death...</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\death...</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\death...</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\smoke...</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\smoke...</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\smoke...</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\smoke...</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\smoke...</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>507 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 image action\n",
       "0    E:\\Project 103\\Trimmed Data\\train_frames\\death...  death\n",
       "1    E:\\Project 103\\Trimmed Data\\train_frames\\death...  death\n",
       "2    E:\\Project 103\\Trimmed Data\\train_frames\\death...  death\n",
       "3    E:\\Project 103\\Trimmed Data\\train_frames\\death...  death\n",
       "4    E:\\Project 103\\Trimmed Data\\train_frames\\death...  death\n",
       "..                                                 ...    ...\n",
       "502  E:\\Project 103\\Trimmed Data\\train_frames\\smoke...  smoke\n",
       "503  E:\\Project 103\\Trimmed Data\\train_frames\\smoke...  smoke\n",
       "504  E:\\Project 103\\Trimmed Data\\train_frames\\smoke...  smoke\n",
       "505  E:\\Project 103\\Trimmed Data\\train_frames\\smoke...  smoke\n",
       "506  E:\\Project 103\\Trimmed Data\\train_frames\\smoke...  smoke\n",
       "\n",
       "[507 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image = pd.read_csv(os.path.join(dataset_path, 'train_frames.csv'))\n",
    "train_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(507, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\death_1...</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\death_1...</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\death_1...</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\death_1...</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\death_1...</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\smoke_9...</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\smoke_9...</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\smoke_9...</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\smoke_9...</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\smoke_9...</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 image action\n",
       "0    E:\\Project 103\\Trimmed Data\\val_frames\\death_1...  death\n",
       "1    E:\\Project 103\\Trimmed Data\\val_frames\\death_1...  death\n",
       "2    E:\\Project 103\\Trimmed Data\\val_frames\\death_1...  death\n",
       "3    E:\\Project 103\\Trimmed Data\\val_frames\\death_1...  death\n",
       "4    E:\\Project 103\\Trimmed Data\\val_frames\\death_1...  death\n",
       "..                                                 ...    ...\n",
       "159  E:\\Project 103\\Trimmed Data\\val_frames\\smoke_9...  smoke\n",
       "160  E:\\Project 103\\Trimmed Data\\val_frames\\smoke_9...  smoke\n",
       "161  E:\\Project 103\\Trimmed Data\\val_frames\\smoke_9...  smoke\n",
       "162  E:\\Project 103\\Trimmed Data\\val_frames\\smoke_9...  smoke\n",
       "163  E:\\Project 103\\Trimmed Data\\val_frames\\smoke_9...  smoke\n",
       "\n",
       "[164 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image = pd.read_csv(os.path.join(dataset_path, 'val_frames.csv'))\n",
    "val_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 2)\n"
     ]
    }
   ],
   "source": [
    "print(val_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['death', 'kill', 'smoke']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_values = list(train_image['action'].unique())\n",
    "action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class_columns(df):\n",
    "    for value in action_values:\n",
    "        df[value] = np.where(df['action'].str.contains(value), 1, 0)\n",
    "    df.drop('action', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>death</th>\n",
       "      <th>kill</th>\n",
       "      <th>smoke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\death...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\death...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\death...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\death...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\train_frames\\death...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  death  kill  smoke\n",
       "0  E:\\Project 103\\Trimmed Data\\train_frames\\death...      1     0      0\n",
       "1  E:\\Project 103\\Trimmed Data\\train_frames\\death...      1     0      0\n",
       "2  E:\\Project 103\\Trimmed Data\\train_frames\\death...      1     0      0\n",
       "3  E:\\Project 103\\Trimmed Data\\train_frames\\death...      1     0      0\n",
       "4  E:\\Project 103\\Trimmed Data\\train_frames\\death...      1     0      0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_class_columns(train_image)\n",
    "train_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>death</th>\n",
       "      <th>kill</th>\n",
       "      <th>smoke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\death_1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\death_1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\death_1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\death_1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\Project 103\\Trimmed Data\\val_frames\\death_1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  death  kill  smoke\n",
       "0  E:\\Project 103\\Trimmed Data\\val_frames\\death_1...      1     0      0\n",
       "1  E:\\Project 103\\Trimmed Data\\val_frames\\death_1...      1     0      0\n",
       "2  E:\\Project 103\\Trimmed Data\\val_frames\\death_1...      1     0      0\n",
       "3  E:\\Project 103\\Trimmed Data\\val_frames\\death_1...      1     0      0\n",
       "4  E:\\Project 103\\Trimmed Data\\val_frames\\death_1...      1     0      0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_class_columns(val_image)\n",
    "val_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_array_and_split(image_data):\n",
    "    image_value = []\n",
    "    for i in tqdm(range(image_data.shape[0])):\n",
    "        img = image.load_img(image_data['image'][i], target_size=(224,224,3))\n",
    "        img = image.img_to_array(img)\n",
    "        # normalizing the pixel value\n",
    "        img = img / 255\n",
    "        image_value.append(img)\n",
    "\n",
    "    X = np.array(image_value)\n",
    "    y = image_data\n",
    "    y.drop('image', axis='columns', inplace=True)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 507/507 [00:13<00:00, 36.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(507, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = convert_to_array_and_split(train_image)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 164/164 [00:03<00:00, 43.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val = convert_to_array_and_split(val_image)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'warning'\n",
    "X_train_set_copy = X_train\n",
    "X_val_set_copy = X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_set_copy\n",
    "X_val = X_val_set_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507, 224, 224, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>death</th>\n",
       "      <th>kill</th>\n",
       "      <th>smoke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   death  kill  smoke\n",
       "0      1     0      0\n",
       "1      1     0      0\n",
       "2      1     0      0\n",
       "3      1     0      0\n",
       "4      1     0      0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "'''This model was trained on a dataset that has 1,000 classes. \n",
    "include_top = False will remove the last layer of this model so that we can tune it as per our need.\n",
    "'''\n",
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507, 7, 7, 512)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = base_model.predict(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 7, 7, 512)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = base_model.predict(X_val)\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'warning'\n",
    "X_train_copy = X_train\n",
    "X_val_copy = X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_copy\n",
    "X_val = X_val_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 7*7*512)\n",
    "X_val = X_val.reshape(X_val.shape[0], 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(507, 25088)\n",
      "(164, 25088)\n"
     ]
    }
   ],
   "source": [
    "max_pixel = X_train.max()\n",
    "X_train = X_train / max_pixel\n",
    "X_val = X_val / max_pixel\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 13,010,179\n",
      "Trainable params: 13,010,179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(25088,)))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_weight = ModelCheckpoint('weight_vgg16_final3_1.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 1.0899 - accuracy: 0.3730 - val_loss: 0.9350 - val_accuracy: 0.4939\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.9926 - accuracy: 0.5263 - val_loss: 0.7820 - val_accuracy: 0.6829\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.8251 - accuracy: 0.6233 - val_loss: 0.6646 - val_accuracy: 0.7195\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.6580 - accuracy: 0.7046 - val_loss: 0.5694 - val_accuracy: 0.7195\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.5526 - accuracy: 0.7352 - val_loss: 0.5276 - val_accuracy: 0.7195\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.5026 - accuracy: 0.7825 - val_loss: 0.5203 - val_accuracy: 0.7378\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.4092 - accuracy: 0.8403 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.3538 - accuracy: 0.8471 - val_loss: 0.4971 - val_accuracy: 0.7378\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.3128 - accuracy: 0.8910 - val_loss: 0.4757 - val_accuracy: 0.7805\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.3238 - accuracy: 0.8800 - val_loss: 0.4872 - val_accuracy: 0.7744\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.2543 - accuracy: 0.9061 - val_loss: 0.4745 - val_accuracy: 0.7927\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.1754 - accuracy: 0.9461 - val_loss: 0.4789 - val_accuracy: 0.7744\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1597 - accuracy: 0.9508 - val_loss: 0.5094 - val_accuracy: 0.7927\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1631 - accuracy: 0.9274 - val_loss: 0.5083 - val_accuracy: 0.7988\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1462 - accuracy: 0.9456 - val_loss: 0.4979 - val_accuracy: 0.7988\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0991 - accuracy: 0.9759 - val_loss: 0.4899 - val_accuracy: 0.8110\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0907 - accuracy: 0.9741 - val_loss: 0.4898 - val_accuracy: 0.8232\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0530 - accuracy: 0.9935 - val_loss: 0.5091 - val_accuracy: 0.8110\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0613 - accuracy: 0.9914 - val_loss: 0.5408 - val_accuracy: 0.7988\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0341 - accuracy: 0.9924 - val_loss: 0.5901 - val_accuracy: 0.8232\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[mcp_weight], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [01:29<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats as s\n",
    "predict = []\n",
    "actual = []\n",
    "if not os.path.exists(test_frames_path):\n",
    "    os.makedirs(test_frames_path)\n",
    "\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    video_file = test['Video_url'][i]\n",
    "    action = test['action'][i]\n",
    "    video_name_list = video_file.split('/')[-1].split('.')\n",
    "    video_name_list = video_name_list[:-1]\n",
    "    video_name = \"\"\n",
    "    for n in video_name_list:\n",
    "        video_name += n\n",
    "    # capturing the video from the given path\n",
    "    capture = cv2.VideoCapture(video_file) \n",
    "    #frame rate\n",
    "    frame_rate = capture.get(5)\n",
    "    count = 0\n",
    "    files = glob(test_frames_path + '/*')\n",
    "    #removing all files from folder\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    while(capture.isOpened()):\n",
    "        #current frame number\n",
    "        frame_id = capture.get(1) \n",
    "        read_correctly, frame = capture.read()\n",
    "        if not read_correctly:\n",
    "            break\n",
    "        if (frame_id % math.floor(frame_rate) == 0):\n",
    "            # storing the frames in a new folder named train_1\n",
    "            filename = test_frames_path + \"/\" + video_name + \"_frame{}_\".format(count) + action +\".jpg\"\n",
    "            count += 1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    capture.release()\n",
    "    \n",
    "    # reading all the frames from temp folder\n",
    "    images = glob(test_frames_path + '/*.jpg')\n",
    "    prediction_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = image.load_img(images[i], target_size=(224,224,3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img / 255\n",
    "        prediction_images.append(img)\n",
    "        \n",
    "    # converting all the frames for a test video into numpy array\n",
    "    prediction_images = np.array(prediction_images)\n",
    "    #prediction_images = prediction_images / max_pixel\n",
    "    # extracting features using pre-trained model\n",
    "    prediction_images = base_model.predict(prediction_images)\n",
    "    # converting features in one dimensional array\n",
    "    prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
    "    # predicting tags for each array\n",
    "    prediction = np.argmax(model.predict(prediction_images), axis=-1)\n",
    "    # appending the mode of predictions in predict list to assign the tag to the video\n",
    "    predict.append(y_train.columns.values[s.mode(prediction)[0][0]])\n",
    "    # appending the actual tag of the video\n",
    "    actual.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.24590163934425"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "'''This model was trained on a dataset that has 1,000 classes. \n",
    "include_top = False will remove the last layer of this model so that we can tune it as per our need.\n",
    "'''\n",
    "base_model = Xception(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735, 7, 7, 2048)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = base_model.predict(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235, 7, 7, 2048)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = base_model.predict(X_val)\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'warning'\n",
    "X_train_copy = X_train\n",
    "X_val_copy = X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_copy\n",
    "X_val = X_val_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(735, 100352)\n",
      "(235, 100352)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 103,451,012\n",
      "Trainable params: 103,451,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.0530 - accuracy: 0.2798 - val_loss: 1.2501 - val_accuracy: 0.5191\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 5s 1s/step - loss: 2.0501 - accuracy: 0.3494 - val_loss: 1.2501 - val_accuracy: 0.4638\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 5s 1s/step - loss: 1.7090 - accuracy: 0.3953 - val_loss: 1.1394 - val_accuracy: 0.5064\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 5s 1s/step - loss: 1.4830 - accuracy: 0.4244 - val_loss: 1.1295 - val_accuracy: 0.5447\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.2641 - accuracy: 0.4718 - val_loss: 1.0914 - val_accuracy: 0.5702\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 5s 1s/step - loss: 1.1819 - accuracy: 0.5221 - val_loss: 1.0167 - val_accuracy: 0.5702\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.0772 - accuracy: 0.5169 - val_loss: 0.9637 - val_accuracy: 0.5830\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.9868 - accuracy: 0.5748 - val_loss: 0.9556 - val_accuracy: 0.5872\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.8744 - accuracy: 0.6321 - val_loss: 0.9350 - val_accuracy: 0.5660\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7964 - accuracy: 0.6186 - val_loss: 0.8916 - val_accuracy: 0.5957\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.8163 - accuracy: 0.6419 - val_loss: 0.8695 - val_accuracy: 0.6213\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.7904 - accuracy: 0.6528 - val_loss: 0.8707 - val_accuracy: 0.6043\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6517 - accuracy: 0.7126 - val_loss: 0.8761 - val_accuracy: 0.6383\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6995 - accuracy: 0.7064 - val_loss: 0.8971 - val_accuracy: 0.6255\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6496 - accuracy: 0.7274 - val_loss: 0.8928 - val_accuracy: 0.6340\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.5814 - accuracy: 0.7367 - val_loss: 0.9140 - val_accuracy: 0.6340\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.5376 - accuracy: 0.7501 - val_loss: 0.9053 - val_accuracy: 0.6298\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.5400 - accuracy: 0.7636 - val_loss: 0.9404 - val_accuracy: 0.6340\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.5006 - accuracy: 0.7840 - val_loss: 0.9454 - val_accuracy: 0.6085\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.5507 - accuracy: 0.7750 - val_loss: 0.9465 - val_accuracy: 0.6426\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.4687 - accuracy: 0.7997 - val_loss: 0.9884 - val_accuracy: 0.6213\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.4668 - accuracy: 0.8061 - val_loss: 1.0565 - val_accuracy: 0.6255\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.3881 - accuracy: 0.8420 - val_loss: 1.1058 - val_accuracy: 0.6340\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.4018 - accuracy: 0.8276 - val_loss: 1.1531 - val_accuracy: 0.6170\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.3544 - accuracy: 0.8565 - val_loss: 1.2360 - val_accuracy: 0.6085\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.3264 - accuracy: 0.8519 - val_loss: 1.2829 - val_accuracy: 0.6170\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.3092 - accuracy: 0.8790 - val_loss: 1.4085 - val_accuracy: 0.6383\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.3055 - accuracy: 0.8781 - val_loss: 1.3644 - val_accuracy: 0.6511\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.2774 - accuracy: 0.8952 - val_loss: 1.2921 - val_accuracy: 0.6298\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.2501 - accuracy: 0.8973 - val_loss: 1.4159 - val_accuracy: 0.6255\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 7*7*2048)\n",
    "X_val = X_val.reshape(X_val.shape[0], 7*7*2048)\n",
    "\n",
    "max_pixel = X_train.max()\n",
    "X_train = X_train / max_pixel\n",
    "X_val = X_val / max_pixel\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(100352,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_weight = ModelCheckpoint('weight_xception_final1_1.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "history=model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val), callbacks=[mcp_weight], batch_size=147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 81/81 [01:30<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats as s\n",
    "predict = []\n",
    "actual = []\n",
    "if not os.path.exists(test_frames_path):\n",
    "    os.makedirs(test_frames_path)\n",
    "\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    video_file = test['Video_url'][i]\n",
    "    action = test['action'][i]\n",
    "    video_name_list = video_file.split('/')[-1].split('.')\n",
    "    video_name_list = video_name_list[:-1]\n",
    "    video_name = \"\"\n",
    "    for n in video_name_list:\n",
    "        video_name += n\n",
    "    # capturing the video from the given path\n",
    "    capture = cv2.VideoCapture(video_file) \n",
    "    #frame rate\n",
    "    frame_rate = capture.get(5)\n",
    "    count = 0\n",
    "    files = glob(test_frames_path + '/*')\n",
    "    #removing all files from folder\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    while(capture.isOpened()):\n",
    "        #current frame number\n",
    "        frame_id = capture.get(1) \n",
    "        read_correctly, frame = capture.read()\n",
    "        if not read_correctly:\n",
    "            break\n",
    "        if (frame_id % math.floor(frame_rate) == 0):\n",
    "            # storing the frames in a new folder named train_1\n",
    "            filename = test_frames_path + \"/\" + video_name + \"_frame{}_\".format(count) + action +\".jpg\"\n",
    "            count += 1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    capture.release()\n",
    "    \n",
    "    # reading all the frames from temp folder\n",
    "    images = glob(test_frames_path + '/*.jpg')\n",
    "    prediction_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = image.load_img(images[i], target_size=(224,224,3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img / 255\n",
    "        prediction_images.append(img)\n",
    "        \n",
    "    # converting all the frames for a test video into numpy array\n",
    "    prediction_images = np.array(prediction_images)\n",
    "    #prediction_images = prediction_images / max_pixel\n",
    "    # extracting features using pre-trained model\n",
    "    prediction_images = base_model.predict(prediction_images)\n",
    "    # converting features in one dimensional array\n",
    "    prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*2048)\n",
    "    # predicting tags for each array\n",
    "    prediction = np.argmax(model.predict(prediction_images), axis=-1)\n",
    "    # appending the mode of predictions in predict list to assign the tag to the video\n",
    "    predict.append(y_train.columns.values[s.mode(prediction)[0][0]])\n",
    "    # appending the actual tag of the video\n",
    "    actual.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.8395061728395"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_no(video_name):\n",
    "    cap= cv2.VideoCapture(video_name)\n",
    "    i=0\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "    \n",
    "        frameId = cap.get(1)\n",
    "    \n",
    "    #cap.release()\n",
    "    #cv2.destroyAllWindows()\n",
    "    return frameId\n",
    "\n",
    "filepath = 'E:\\Project 103\\prediction_count'\n",
    "j=0\n",
    "video_name = 'kill_69.mp4'\n",
    "frame_needed = 30\n",
    "cap= cv2.VideoCapture(video_name)\n",
    "#frameRate = cap.get(5)\n",
    "tot_frame = frame_no(video_name)\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    frameId = cap.get(1)\n",
    "\n",
    "    a = np.linspace(0, tot_frame, frame_needed)\n",
    "\n",
    "    for i in range(len(a)):\n",
    "        if (frameId == math.floor(a[i])):\n",
    "            final_filepath = os.path.join(filepath, 'predict_frame'+str(j)+'.jpg')\n",
    "            cv2.imwrite(final_filepath,frame)\n",
    "            j+=1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n"
     ]
    }
   ],
   "source": [
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "end_time = 150\n",
    "start_time = 90\n",
    "clip = VideoFileClip(\"z3.mp4\")\n",
    "dur_int = int(clip.duration)\n",
    "ffmpeg_extract_subclip(\"z3.mp4\", start_time, end_time, targetname=\"z3short2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0\n",
      " 0 1 1 2 0 0 0 1 1 1 1 1 1 1 2 1 1 1 1 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def frame_no(video_name):\n",
    "    cap= cv2.VideoCapture(video_name)\n",
    "    i=0\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "    \n",
    "        frameId = cap.get(1)\n",
    "    \n",
    "    #cap.release()\n",
    "    #cv2.destroyAllWindows()\n",
    "    return frameId\n",
    "\n",
    "filepath = 'E:\\Project 103\\prediction_count'\n",
    "images = glob(filepath + '/*.jpg')\n",
    "\n",
    "for f in images:\n",
    "    os.remove(f)\n",
    "\n",
    "filepath = 'E:\\Project 103\\prediction_count'\n",
    "j=0\n",
    "video_name = 'z3short2.mp4'\n",
    "\n",
    "cap= cv2.VideoCapture(video_name)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)     \n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = int(frame_count/fps)\n",
    "\n",
    "frame_needed = duration*2\n",
    "\n",
    "tot_frame = frame_no(video_name)\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    frameId = cap.get(1)\n",
    "\n",
    "    a = np.linspace(0, tot_frame, frame_needed)\n",
    "\n",
    "    for i in range(len(a)):\n",
    "        if (frameId == math.floor(a[i])):\n",
    "            final_filepath = os.path.join(filepath, 'predict_frame'+str(j)+'.jpg')\n",
    "            cv2.imwrite(final_filepath,frame)\n",
    "            j+=1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "images = glob(filepath + '/*.jpg')\n",
    "\n",
    "prediction_images = []\n",
    "predict = []\n",
    "predict2 = []\n",
    "for i in range(len(images)):\n",
    "    img = image.load_img(images[i], target_size=(224,224,3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img / 255\n",
    "    prediction_images.append(img)\n",
    "\n",
    "prediction_images = np.array(prediction_images)\n",
    "prediction_images = base_model.predict(prediction_images)\n",
    "prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
    "predict = model.predict(prediction_images)\n",
    "a = np.argmax(predict)\n",
    "#print(predict)\n",
    "def maxfunction(x):\n",
    "        return np.argmax(x)\n",
    "\n",
    "prediction = np.apply_along_axis( maxfunction, axis=1, arr=predict )\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "filepath = 'E:\\Project 103\\prediction_count'\n",
    "images = glob(filepath + '/*.jpg')\n",
    "\n",
    "for f in images:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kill:  1\n",
      "Death:  6\n"
     ]
    }
   ],
   "source": [
    "z=0\n",
    "kill_count=0\n",
    "death_count=0\n",
    "threshold=7\n",
    "range_=10\n",
    "\n",
    "for i in prediction:\n",
    "    if z>=len(prediction):\n",
    "        break\n",
    "    \n",
    "    elif prediction[z]==1:\n",
    "            prove = prediction[z:(z+range_)]\n",
    "            #print(z,':for 1')\n",
    "            counter=collections.Counter(prove)\n",
    "            dictionary = dict(counter)\n",
    "            try:\n",
    "                if dictionary[1]>=threshold:\n",
    "                    #print('kill!')\n",
    "                    kill_count+=1\n",
    "                    \n",
    "                    z=z+threshold-1\n",
    "                   \n",
    "            except:\n",
    "                #print('oops')\n",
    "                pass\n",
    "            \n",
    "    elif prediction[z]==0:\n",
    "            prove = prediction[z:(z+range_)]\n",
    "            counter=collections.Counter(prove)\n",
    "            dictionary = dict(counter)\n",
    "            #print(z, ':for 2')\n",
    "            try:\n",
    "                if dictionary[0]>=threshold:\n",
    "                    #print('death!')\n",
    "                    \n",
    "                    death_count+=1\n",
    "                    z=z+threshold-1\n",
    "            except:\n",
    "                #print('oops')\n",
    "                pass\n",
    "            \n",
    "    else:\n",
    "        pass\n",
    "    #print(prove)\n",
    "    \n",
    "    z+=1\n",
    "    #print(z)\n",
    "print('Kill: ',kill_count)\n",
    "print('Death: ',death_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'E:\\Project 103\\prediction_count'\n",
    "images = glob(filepath + '/*.jpg')\n",
    "\n",
    "for f in images:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 0\n",
      " 0 0 0 2 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 0 2 2 0 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "def frame_no(video_name):\n",
    "    cap= cv2.VideoCapture(video_name)\n",
    "    i=0\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "    \n",
    "        frameId = cap.get(1)\n",
    "    \n",
    "    #cap.release()\n",
    "    #cv2.destroyAllWindows()\n",
    "    return frameId\n",
    "\n",
    "filepath = 'E:\\Project 103\\prediction_count'\n",
    "j=0\n",
    "video_name = 'z1short.mp4'\n",
    "\n",
    "cap= cv2.VideoCapture(video_name)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)     \n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = int(frame_count/fps)\n",
    "\n",
    "frame_needed = duration*2\n",
    "\n",
    "tot_frame = frame_no(video_name)\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    frameId = cap.get(1)\n",
    "\n",
    "    a = np.linspace(0, tot_frame, frame_needed)\n",
    "\n",
    "    for i in range(len(a)):\n",
    "        if (frameId == math.floor(a[i])):\n",
    "            final_filepath = os.path.join(filepath, 'predict_frame'+str(j)+'.jpg')\n",
    "            cv2.imwrite(final_filepath,frame)\n",
    "            j+=1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "images = glob(filepath + '/*.jpg')\n",
    "\n",
    "prediction_images = []\n",
    "predict = []\n",
    "predict2 = []\n",
    "for i in range(len(images)):\n",
    "    img = image.load_img(images[i], target_size=(224,224,3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img / 255\n",
    "    prediction_images.append(img)\n",
    "\n",
    "prediction_images = np.array(prediction_images)\n",
    "prediction_images = base_model.predict(prediction_images)\n",
    "prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
    "predict = model.predict(prediction_images)\n",
    "a = np.argmax(predict)\n",
    "#print(predict)\n",
    "def maxfunction(x):\n",
    "        return np.argmax(x)\n",
    "\n",
    "prediction2 = np.apply_along_axis( maxfunction, axis=1, arr=predict )\n",
    "\n",
    "print(prediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kill:  0\n",
      "Death:  1\n"
     ]
    }
   ],
   "source": [
    "z=0\n",
    "kill_count=0\n",
    "death_count=0\n",
    "threshold=7\n",
    "range_=10\n",
    "\n",
    "for i in prediction2:\n",
    "    if z>=len(prediction2):\n",
    "        break\n",
    "    \n",
    "    elif prediction2[z]==1:\n",
    "            prove = prediction2[z:(z+range_)]\n",
    "            #print(z,':for 1')\n",
    "            counter=collections.Counter(prove)\n",
    "            dictionary = dict(counter)\n",
    "            try:\n",
    "                if dictionary[1]>=threshold:\n",
    "                    #print('kill!')\n",
    "                    kill_count+=1\n",
    "                    \n",
    "                    z=z+threshold-1\n",
    "                   \n",
    "            except:\n",
    "                #print('oops')\n",
    "                pass\n",
    "    elif prediction2[z]==0:\n",
    "            prove = prediction2[z:(z+range_)]\n",
    "            counter=collections.Counter(prove)\n",
    "            dictionary = dict(counter)\n",
    "            #print(z, ':for 2')\n",
    "            try:\n",
    "                if dictionary[0]>=threshold:\n",
    "                    #print('death!')\n",
    "                    \n",
    "                    death_count+=1\n",
    "                    z=z+threshold-1\n",
    "            except:\n",
    "                #print('oops')\n",
    "                pass\n",
    "    else:\n",
    "        pass\n",
    "    #print(prove)\n",
    "    \n",
    "    z+=1\n",
    "    #print(z)\n",
    "print('Kill: ',kill_count)\n",
    "print('Death: ',death_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3,4,5]\n",
    "a[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kill:  0\n",
      "Death:  1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"z1short.mp4\")\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)     \n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = int(frame_count/fps)\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = prediction[101:108]\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['death', 'kill', 'NoAction'], dtype=object)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Project 103\\prediction_count\\predict_frame0.jpg\n",
      "E:\\Project 103\\prediction_count\\predict_frame1.jpg\n",
      "E:\\Project 103\\prediction_count\\predict_frame2.jpg\n",
      "E:\\Project 103\\prediction_count\\predict_frame3.jpg\n",
      "E:\\Project 103\\prediction_count\\predict_frame4.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in images:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.33333333333333"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kill',\n",
       " 'NoAction',\n",
       " 'NoAction',\n",
       " 'kill',\n",
       " 'NoAction',\n",
       " 'kill',\n",
       " 'NoAction',\n",
       " 'death',\n",
       " 'death',\n",
       " 'death',\n",
       " 'kill',\n",
       " 'NoAction',\n",
       " 'death',\n",
       " 'kill',\n",
       " 'death',\n",
       " 'death',\n",
       " 'kill',\n",
       " 'death',\n",
       " 'death',\n",
       " 'death',\n",
       " 'kill',\n",
       " 'kill',\n",
       " 'NoAction',\n",
       " 'death',\n",
       " 'kill',\n",
       " 'NoAction',\n",
       " 'death',\n",
       " 'NoAction',\n",
       " 'NoAction',\n",
       " 'NoAction',\n",
       " 'kill',\n",
       " 'NoAction',\n",
       " 'death',\n",
       " 'kill',\n",
       " 'death',\n",
       " 'kill',\n",
       " 'kill',\n",
       " 'death',\n",
       " 'NoAction',\n",
       " 'NoAction',\n",
       " 'kill',\n",
       " 'NoAction',\n",
       " 'NoAction',\n",
       " 'kill',\n",
       " 'death',\n",
       " 'death',\n",
       " 'NoAction',\n",
       " 'death',\n",
       " 'death',\n",
       " 'death',\n",
       " 'kill',\n",
       " 'kill',\n",
       " 'NoAction',\n",
       " 'death',\n",
       " 'NoAction',\n",
       " 'kill',\n",
       " 'kill',\n",
       " 'NoAction',\n",
       " 'death',\n",
       " 'NoAction']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'death': 21, 'NoAction': 20, 'kill': 19})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter=collections.Counter(predict)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'death': 20, 'NoAction': 20, 'kill': 20})\n"
     ]
    }
   ],
   "source": [
    "counter=collections.Counter(actual)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 26,380,547\n",
      "Trainable params: 26,380,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"weight_vgg16_final1.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [01:23<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats as s\n",
    "predict = []\n",
    "actual = []\n",
    "if not os.path.exists(test_frames_path):\n",
    "    os.makedirs(test_frames_path)\n",
    "\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    video_file = test['Video_url'][i]\n",
    "    action = test['action'][i]\n",
    "    video_name_list = video_file.split('/')[-1].split('.')\n",
    "    video_name_list = video_name_list[:-1]\n",
    "    video_name = \"\"\n",
    "    for n in video_name_list:\n",
    "        video_name += n\n",
    "    # capturing the video from the given path\n",
    "    capture = cv2.VideoCapture(video_file) \n",
    "    #frame rate\n",
    "    frame_rate = capture.get(5)\n",
    "    count = 0\n",
    "    files = glob(test_frames_path + '/*')\n",
    "    #removing all files from folder\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    while(capture.isOpened()):\n",
    "        #current frame number\n",
    "        frame_id = capture.get(1) \n",
    "        read_correctly, frame = capture.read()\n",
    "        if not read_correctly:\n",
    "            break\n",
    "        if (frame_id % math.floor(frame_rate) == 0):\n",
    "            # storing the frames in a new folder named train_1\n",
    "            filename = test_frames_path + \"/\" + video_name + \"_frame{}_\".format(count) + action +\".jpg\"\n",
    "            count += 1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    capture.release()\n",
    "    \n",
    "    # reading all the frames from temp folder\n",
    "    images = glob(test_frames_path + '/*.jpg')\n",
    "    prediction_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = image.load_img(images[i], target_size=(224,224,3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img / 255\n",
    "        prediction_images.append(img)\n",
    "        \n",
    "    # converting all the frames for a test video into numpy array\n",
    "    prediction_images = np.array(prediction_images)\n",
    "    #prediction_images = prediction_images / max_pixel\n",
    "    # extracting features using pre-trained model\n",
    "    prediction_images = base_model.predict(prediction_images)\n",
    "    # converting features in one dimensional array\n",
    "    prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
    "    # predicting tags for each array\n",
    "    prediction = np.argmax(model.predict(prediction_images), axis=-1)\n",
    "    # appending the mode of predictions in predict list to assign the tag to the video\n",
    "    predict.append(y_train.columns.values[s.mode(prediction)[0][0]])\n",
    "    # appending the actual tag of the video\n",
    "    actual.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_best_train = X_train\n",
    "y_best_train = y_train\n",
    "\n",
    "X_best_val = X_val\n",
    "y_best_val = y_val\n",
    "\n",
    "test_best = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_best.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
